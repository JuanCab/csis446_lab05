{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2S1xz4VkWKWk"
   },
   "source": [
    "IMPORTANT! Before beginning any lab assignment, be sure to **make your own copy** of the notebook and name it \"lastname - Lab 5\" or something similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WppFQvdYNB0p"
   },
   "source": [
    "# Lab 5: Decision Trees in Python\n",
    "\n",
    "In lecture, we have been using a custom built ID3 decision tree implementation to understand how decision trees work. In this lab, we will use the `scikit-learn` library to implement decision trees.  It is a bit different from the ID3 implementation we have been using, but it is a powerful and widely used library for machine learning in Python.\n",
    "\n",
    "We are also going to explore the Evaluation Metrics used to assess the performance of machine learning models.\n",
    "\n",
    "## Part A: Learning about Decision Tree Classifiers in `scikit-learn`\n",
    "\n",
    "Decision trees in `scikit-learn` can be used for both classification and regression tasks. Some of the ideas discussed in lecture for ID3 decision trees, such as feature importance and tree visualization, are also applicable to `scikit-learn` decision trees.  However, they do NOT use the same algorithm or the same splitting criteria (ID3 uses Information Gain, while `scikit-learn` uses Gini Impurity for classification and Mean Squared Error for regression by default)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Get the Data we will use\n",
    "\n",
    "Let's load a dataset about that most excellent of beverages, coffee!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed packages and functions\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "# Set up Polars to show all columns when displaying DataFrames\n",
    "pl.Config.set_tbl_formatting(\"ASCII_FULL_CONDENSED\")\n",
    "pl.Config.set_tbl_cols(-1)\n",
    "\n",
    "# Set the URL and local filename\n",
    "url = \"https://raw.githubusercontent.com/JuanCab/csis446_lab05/refs/heads/main/data/coffee.csv\"\n",
    "local_filename = \"coffee.csv\"\n",
    "\n",
    "# Check if the file already exists to avoid re-downloading\n",
    "if not Path(local_filename).is_file():\n",
    "    print(f\"Downloading dataset from {url}...\")\n",
    "    # Download the dataset using requests library\n",
    "    r = requests.get(url)\n",
    "    # Check if the request was successful, if not, raise an error\n",
    "    r.raise_for_status()\n",
    "\n",
    "    # Save the content to a local file\n",
    "    with open(local_filename, \"wb\") as f:\n",
    "        f.write(r.content)\n",
    "        print(f\"Dataset downloaded and saved as '{local_filename}'.\")\n",
    "\n",
    "# Load the dataset from the local file into a Polars DataFrame\n",
    "coffee_full_df = pl.read_csv(local_filename)\n",
    "\n",
    "# Print number of features (columns) in the DataFrame\n",
    "num_features = coffee_full_df.width\n",
    "print(f\"The dataset contains {num_features} features (columns).\")\n",
    "\n",
    "# This is too many features so we are going to only keep a subset\n",
    "features_to_keep = ['species', 'aroma', 'acidity', 'body', 'flavor', \n",
    "                    'aftertaste', 'balance', 'uniformity', 'sweetness']\n",
    "coffee_df = coffee_full_df.select(features_to_keep)\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify successful loading\n",
    "coffee_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Explore the dataset statistically by getting a summary of the dataset and checking for missing values.  How many unique species are in the dataset? **HINT**: Recall that in Polars, you can use the `.describe()` method to get a statistical summary of the dataframe, and the `.n_unique()` method to get the number of unique values in a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Get a statistical summary of the dataset\n",
    "\n",
    "# TODO: Determine the number of unique species and then add comments \n",
    "# indicating the number of species.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Preparing the Data for `scikit-learn`\n",
    "\n",
    "One of the major restrictions with `scikit-learn` decision tree classes is that they can only handle numerical features.  Categorical features must be converted to numerical features using feature transformation techniques before they can be used with `scikit-learn` decision trees.  Two common techniques are:\n",
    "\n",
    "- **One hot encoding** creates a new binary feature for each category in the original feature. For example, if a feature has three categories (`A`, `B`, `C`), one-hot encoding would create three new features: `is_A`, `is_B`, and `is_C`. Each of these features would be 1 if the original feature was that category, and 0 otherwise.\n",
    "- **Label encoding** assigns a unique integer to each category in the original feature. For example, if a feature has three categories (`A`, `B`, `C`), label encoding would assign 0 to `A`, 1 to `B`, and 2 to `C`. The original feature would then be replaced with these integer values.\n",
    "\n",
    "Our target feature will be the `species` of coffee, which is a categorical feature with two possible values: `Arabica` and `Robusta`. **We will use label encoding** to convert this categorical feature into a numerical feature. This is done by creating a dictionary that maps each species to a unique integer. Then we use the `replace` method to create a new column with the encoded values. Since we only have two species, we can treat the label encoding as a binary feature where 1 indicates Robusta and 0 indicates Arabica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a label encoding for the species. Since we only have two species,\n",
    "# we can treat 'Robusta' as a binary variable where 1 indicates Robusta\n",
    "# and 0 indicates Arabica. (We have to use \"cast\" here because replace\n",
    "# returns the original data type by default)\n",
    "species_mapping = {'Arabica': 0, 'Robusta': 1}\n",
    "coffee_df = coffee_df.with_columns(\n",
    "    pl.col('species').replace(species_mapping).cast(pl.Int64).alias('Robusta')\n",
    ")\n",
    "\n",
    "# Show the first few rows of the updated data\n",
    "coffee_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Explaing how you would need to modify the code above if there were more than two species in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "ENTER YOUR ANSWER HERE\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Fitting the Model in a Way We Can Evaluate\n",
    "\n",
    "For some unfortunate reason, your textbook chooses to address model evaluation *after* discussing all of the models.  However, in practical use, we need to know how well our models are performing in order to improve them and make informed decisions.\n",
    "\n",
    "To assess a model's performance, we typically perform a **test/train split** of the dataset, where the data is split into a training set and a testing set.  The model is trained on the training set and then its performance is evaluated on the testing set.  This helps to ensure that the model is not overfitting to the training data and can generalize well to unseen data (*e.g.* the testing set).\n",
    "\n",
    "Very commonly, we use a 70/30 or 80/20 split for the training and testing sets, respectively.  This means that 70% or 80% of the data is used for training, and the remaining 30% or 20% is used for testing. We can use the `train_test_split()` function from `sklearn.model_selection` to easily split the data into training and testing sets.  \n",
    "\n",
    "The steps are:\n",
    "\n",
    "1. Separate the features we will use in the fit (`X`) and the target variable (`y`).  **Remember you need to convert the Polars DataFrame to a Pandas DataFrame first using the `.to_pandas()` method as `scikit-learn` requires Pandas DataFrames.**\n",
    "2. Use `X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=[some fraction], random_state=42)` to split the data into training and testing sets.  The `test_size` parameter specifies the proportion of the data to use for testing (here it is 20%), and the `random_state` parameter ensures that the split is reproducible (by fixing the random seed).\n",
    "3. Train the model (in this case, a decision tree classifier) using the training data.\n",
    "4. Use the trained model to make predictions on the testing data and compare those answers to the actual labels.\n",
    "\n",
    "#### Modelling Step 1: Separate the Features and Target Variable\n",
    "\n",
    "**Question**: Modify the code below to:\n",
    "\n",
    "- `.select()` `uniformity` and `sweetness` as input features (`X`).  Remember to convert the result to a Pandas DataFrame using the `.to_pandas()` method.\n",
    "- `.select()` the `Robusta` column as the target variable (`y`).  Remember to convert the result to a Pandas Series using the `.to_pandas()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Select the input features using Polars syntax and convert to pandas\n",
    "X = ...\n",
    "\n",
    "# TODO: Select the target variable\n",
    "y = ...\n",
    "\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelling Step 2: Create Training and Testing Data\n",
    "\n",
    "**Question**: Modify the code below to perform a 70/30 split of the data, producing `X_train`, `X_test`, `y_train`, and `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TODO: Create training and testing data with a test size of 30% and \n",
    "# random state of 123\n",
    "X_train, X_test, y_train, y_test = train_test_split(...)\n",
    "\n",
    "# Show the shapes of the resulting datasets to verify the split\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'X_test shape: {X_test.shape}')\n",
    "print(f'y_train shape: {y_train.shape}')\n",
    "print(f'y_test shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: The cell below is going to produce a scatter plot of the training data where the points are colored based on their species.  Explain why this suggests a decision tree might work well for this dataset (**Hint**: Decision trees will split continuous features into binary splits.  A split of `uniformity` at 8.5 would mean all points with `uniformity` <= 8.5 go to one side of the tree ... how would this help in identifying the species?).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Scatter plot of the input features colored by species of coffee\n",
    "p1 = sns.scatterplot(data=X_train, \n",
    "                     x='uniformity', y='sweetness', \n",
    "                     hue=y_train['Robusta'], alpha=0.5)\n",
    "p1.set(xlabel='Uniformity', ylabel='Sweetness')\n",
    "p1.get_legend().set_title('Robusta?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "ENTER YOUR ANSWER HERE\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelling Step 3: Train the Model\n",
    "\n",
    "For this example, we want to use as a model a decision tree classifier to predict the species of coffee based on the `uniformity` and `sweetness` features.\n",
    "\n",
    "Decision tree classifiers are implemented in `sklearn.tree` using [`DecisionTreeClassifier()`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html). They do not use the same algorithm as ID3,  but they do share some similar concepts.  Here are some important parameters and methods to be aware of:\n",
    "\n",
    "- The `criterion` parameter specifies the function to measure the \"information gain\" of a split.  The default is `gini` for Gini Impurity, but you can also use `entropy` for Information Gain.\n",
    "- The `max_depth` parameter specifies the maximum depth of the tree.  Limiting the depth can help prevent overfitting.\n",
    "- The `.get_depth()` method can be used to get the depth of the tree.  This corresponds to how many questions are needed to identify the target label.\n",
    "\n",
    "The following functions from `sklearn.tree` are also useful for visualizing and interpreting decision trees:\n",
    "\n",
    "- `plot_tree()`: Plots the decision tree.\n",
    "- `export_text()`: Exports the decision tree as text.\n",
    "\n",
    "Now let's initialize and fit a decision tree classifier to the training data.  You'll notice the result is not quite as simple as the decision tree we saw earlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_text, plot_tree\n",
    "\n",
    "# Initialize the tree and fit the tree using the default parameters\n",
    "coffee_clf = DecisionTreeClassifier()\n",
    "coffee_clf.fit(X_train.values,y_train)\n",
    "\n",
    "# Print the depth of the tree\n",
    "print(f'The depth of the tree is {coffee_clf.get_depth()}')\n",
    "\n",
    "# Show the tree as text. export_text() accepts the classifier model\n",
    "# and the feature names (which are the column names of X_train)\n",
    "print(export_text(coffee_clf, feature_names=X_train.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The printed tree shows the splits made at each node, the number of samples at each node, the distribution of classes at each node, and the predicted class for each leaf node.  Let's visualize the tree using `plot_tree()`.  It uses the same arguments as `export_text()`, but produces a graphical representation of the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# We will force the Decision Tree plot to be large so details can be seen\n",
    "plt.figure(figsize=(20, 20))  # Width=20, Height=20 inches\n",
    "\n",
    "# TODO: Plot the fitted tree. We set fontsize to keep the text readable and\n",
    "# filled to color the boxes.  We assign to dummy variable _ to avoid text \n",
    "# output since this is the last line of the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelling Step 4: Evaluate the Model using Predictions based on the Test Set\n",
    "\n",
    "This is the part that your textbook has been delaying.  How do we know if our model is any good?  We can use several evaluation metrics to assess the performance of our decision tree classifier using the test data which was NOT used during training.\n",
    "\n",
    "For a classifier, one of the obvious metrics is **accuracy**, which is the proportion of correct predictions made by the model Scikit-learn provides a convenient function called `accuracy_score()` in the `sklearn.metrics` module to calculate accuracy.  It takes two arguments: the true labels and the predicted labels. \n",
    "\n",
    "So let's see how accurate the decision tree classifier we trained is on the test data. We will use the `.predict()` method of the trained model to make predictions on the test data, `X_test`, saving the predicted labels as `y_predict`.  We know the actual labels (they are `y_test`) so we can use `accuracy_score()` to calculate the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Predict species for the test set.\n",
    "# We need to use .values to convert from X_test DataFrame to an array\n",
    "# which is what the .predict() method expects\n",
    "y_pred = coffee_clf.predict(X_test.values)\n",
    "\n",
    "# Print the accuracy\n",
    "print('accuracy:', accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: So how accurate is our decision tree classifier on the test data?  Is this good or bad?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "ENTER YOUR ANSWER HERE.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " However, accuracy alone can be misleading, especially if the classes are imbalanced.  It can also be informative to look at what is referred to as the **confusion matrix**, which shows the number of true positives, true negatives, false positives, and false negatives. Scikit-learn provides a convenient function called `confusion_matrix()` in the `sklearn.metrics` module to compute the confusion matrix.  It takes two arguments: the true labels and the predicted labels. You can then visualize the confusion matrix using `ConfusionMatrixDisplay()`.  Let's do so below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the confusion matrix labelled with species names\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "ConfusionMatrixDisplay(cm, display_labels=['Arabica', 'Robusta']).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: What is the confusion matrix for our decision tree classifier on the test data tell you about the model's performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "ENTER YOUR ANSWER HERE.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: The confusion matrix does suggest a problem with using accuracy alone to evaluate the model. What is it?  **HINT**: How many Robusta coffees were in the test set compared to Arabica?  What if we just classified everything as Arabica?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "ENTER YOUR ANSWER HERE\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B: Practicing Building a Decision Tree Classifier\n",
    "\n",
    "Let's re-perform this analysis using the input features of `aroma` and `aftertaste` instead of `sweetness` and `uniformity`.  The next cell will go through all of the steps again, but using these new features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Separate the Features and Target Variable\n",
    "\n",
    "Separate the features `aroma` and `aftertaste` into our input features variable (`X2`) and continue to use the numerical `Robusta` feature as the target variable (`y2`).  Remember to convert the Polars DataFrame to a Pandas DataFrame first using the `.to_pandas()` method as `scikit-learn` requires Pandas DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Select the input features using Polars syntax and convert to pandas\n",
    "X2 = ...\n",
    "\n",
    "# TODO: Select the target variable\n",
    "y2 = ...\n",
    "\n",
    "# Print the features and target variable to verify if they look reasonable\n",
    "print(X2)\n",
    "print(y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Based on the plot above, do you think a decision tree will perform well on this dataset?  Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "ENTER YOUR ANSWER HERE\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create Training and Testing Data\n",
    "\n",
    "Use an 80/20 split (instead of the 70/30 split we used previously) of the data, producing `X2_train`, `X2_test`, `y2_train`, and `y2_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TODO: Create training and testing data with a test size of 20% and \n",
    "# random state of 123\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(...)\n",
    "\n",
    "# Show the shapes of the resulting datasets to verify the split\n",
    "print(f'X2_train shape: {X2_train.shape}')\n",
    "print(f'X2_test shape: {X2_test.shape}')\n",
    "print(f'y2_train shape: {y2_train.shape}')\n",
    "print(f'y2_test shape: {y2_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot this data up to see how well these features separate the two species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Scatter plot of the input features colored by species of coffee\n",
    "p1 = sns.scatterplot(data=X2_train, \n",
    "                     x='aroma', y='aftertaste', \n",
    "                     hue=y2_train['Robusta'], alpha=0.5)\n",
    "p1.set(xlabel='Aroma', ylabel='Aftertaste')\n",
    "p1.get_legend().set_title('Robusta?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Based on the plot above, do you think a decision tree will perform well on this dataset?  Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "ENTER YOUR ANSWER HERE\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train the Model\n",
    "\n",
    "Now train a new decision tree classifier using the new training data, call it `coffee_clf2`, and fit it to the training data.  Plot the tree using `plot_tree()` and print the depth of the tree using the `.get_depth()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_text, plot_tree\n",
    "\n",
    "# TODO: Train the Model, then print the depth and plot the tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: What is different about this tree compared to the previous one?  Why do you think this is?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "ENTER YOUR ANSWER HERE.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Evaluate the Model using Predictions based on the Test Set\n",
    "\n",
    "Determine the accuracy of this new decision tree classifier on the test data and display the confusion matrix.  Comment on the results in your code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TODO: Evaluate the Model using Predictions based on the Test Set\n",
    "\n",
    "\n",
    "# TODO: Comment on the results of using these two features for classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CAHRdBjQNidG"
   },
   "source": [
    "## Part C: Using a Decision Tree Regressor\n",
    "\n",
    "Decision trees can also be used for regression tasks, where the target variable is continuous rather than categorical. In `scikit-learn`, decision tree regression is implemented using the `DecisionTreeRegressor` class from the `sklearn.tree` module.\n",
    "\n",
    "We can follow similar steps as we did for classification, but now we will be predicting a continuous variable.  This means the decision tree regressor, rather than trying to maximize information gain or Gini impurity at each split, will try to minimize the variance within each leaf node. This means we need to also change how we evaluate the results.  \n",
    "\n",
    "The most common evaluation metric for regression tasks is the **Mean Squared Error (MSE)**, which measures the average squared difference between the predicted and actual values. A lower MSE indicates better model performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dKQ0ctwqQagN"
   },
   "source": [
    "### Step 1: Load & Explore the Data\n",
    "\n",
    "Load the California Housing dataset and inspect its basic properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "executionInfo": {
     "elapsed": 3536,
     "status": "ok",
     "timestamp": 1740111563238,
     "user": {
      "displayName": "Ronni Kurtzhals",
      "userId": "06703412593860866078"
     },
     "user_tz": 360
    },
    "id": "aT2SS3-zq5uI",
    "outputId": "d4a2d10e-756f-45b6-9479-83fd12e82075"
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Load the California Housing dataset built-in to scikit-learn\n",
    "data = fetch_california_housing()\n",
    "\n",
    "# Load all the input features into a Polars DataFrame\n",
    "cali_housing_df = pl.DataFrame(data.data, schema=data.feature_names)\n",
    "\n",
    "# Add the target feature (median house value in $100,000s) to the DataFrame\n",
    "cali_housing_df = cali_housing_df.with_columns(pl.lit(data.target).alias(\"MedValue\"))\n",
    "\n",
    "# Get a list of all feature names except the target\n",
    "feature_names = [name for name in cali_housing_df.columns if name != \"MedValue\"]\n",
    "print(f'Feature names: {feature_names}')\n",
    "\n",
    "# Show the first few rows of the dataset\n",
    "cali_housing_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: What do you think the input features and target variable represent in this dataset?  Which might you expect to be most important for predicting the target variable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "ENTER YOUR ANSWER HERE.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: You can try to confirm your answer by checking the correlation coefficient between each input feature and the target feature of `MedValue`. Is your answer confirmed or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's run through all the input features (in feature_names) and compute\n",
    "# their correlation coefficient (R^2) with the target `MedValue` feature.\n",
    "\n",
    "# Use polars correlation coefficient method to compute these.\n",
    "corr_matrix = cali_housing_df.corr()\n",
    "\n",
    "# Pull the `MedValue` column of values (I can cut off the last column\n",
    "# because I know it is `MedValue` given how I tacked it on at the end \n",
    "# of cali_housing_df above.  This is is not a general solution)\n",
    "for i, feature in enumerate(corr_matrix.columns[:-1]):\n",
    "    # Pull row i value from `MedValue` column\n",
    "    R2 = corr_matrix[\"MedValue\"][i]\n",
    "    print(f\"{feature:>10}: {R2:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "ENTER YOUR ANSWER HERE.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PgUeUoGAQaM_"
   },
   "source": [
    "### Step 2: Split Data for Training & Testing\n",
    "\n",
    "Your tasks:\n",
    "\n",
    "- Define **features (X) and target (y)**.\n",
    "- Split into **80% training, 20% testing** with a random state of 42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1740111629151,
     "user": {
      "displayName": "Ronni Kurtzhals",
      "userId": "06703412593860866078"
     },
     "user_tz": 360
    },
    "id": "FTximDhivDlt",
    "outputId": "23e483a6-d4fa-4b82-bda6-225d01ad55a3"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TODO: Define features (X) and target variable (y)\n",
    "X = ...\n",
    "y = ...\n",
    "\n",
    "# TODO: Split the dataset into training (80%) and testing (20%) sets\n",
    "# and set random_state to 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(...)\n",
    "\n",
    "# Print dataset shapes\n",
    "print(f\"Training Set: {X_train.shape}, Testing Set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: We won't have you plot the data this time since it is higher dimensional, but you can still visualize the results later.  Keep in mind, this means you are going into this a little bit blindly, without knowing how well the features separate the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CGmHGgpxQZ4w"
   },
   "source": [
    "### Step 3: Train a Decision Tree Regressor\n",
    "\n",
    "We'll train a **DecisionTreeRegressor** to predict housing prices. This is done similarly to the classifier, but using the regressor class, `DecisionTreeRegressor`.  The parameters are similar to those of the `DecisionTreeClassifier` except that the splitting criteria is not based on Information Gain but instead defaults to minimizing Mean Squared Error (MSE).\n",
    "\n",
    "So build a regressor called `pricing_model` by training it on `X_train`, check its depth, and visualize the tree using `plot_tree()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 131,
     "status": "ok",
     "timestamp": 1740111699717,
     "user": {
      "displayName": "Ronni Kurtzhals",
      "userId": "06703412593860866078"
     },
     "user_tz": 360
    },
    "id": "vL_4qkG4MVpj",
    "outputId": "dd32f186-2993-4454-981b-c88f71445f09"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor, plot_tree, export_text\n",
    "\n",
    "# TODO: Initialize a Decision Tree Regressor to predict housing prices\n",
    "pricing_model = ...\n",
    "\n",
    "# TODO: Train the model on the training data\n",
    "\n",
    "# TODO: Print tree depth\n",
    "\n",
    "# TODO: Print the tree as text, but limit to max depth of 3 for readability\n",
    "# Hint: use the \"max_depth\" parameter of export_text\n",
    "\n",
    "# Create a larger figure for better visibility\n",
    "plt.figure(figsize=(20, 12))  # Width=20, Height=12 inches\n",
    "\n",
    "# TODO: Plot the tree but limit the depth to 3 for better visualization\n",
    "# Hint: use the \"max_depth\" parameter of plot_tree\n",
    "\n",
    "# Add title (assign to dummy variable to avoid text output)\n",
    "_ = plt.title(\"Decision Tree Visualization (Limited to Depth 3)\", fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: What are the first three splits in the tree (covering the first 2 levels)?  What do they indicate about the importance of the features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "ENTER YOUR ANSWER HERE\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRVxvsTp5fm_"
   },
   "source": [
    "**Question:** What does tree depth tell us about the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "ENTER YOUR ANSWER HERE\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZc2NejlR7j4"
   },
   "source": [
    "### Step 4: Evaluate Model Performance\n",
    "\n",
    "With a classifier, we used accuracy and the confusion matrix to evaluate performance. Since this is a **regression task**, we'll use **Root Mean Squared Error (RMSE)** of the output continuous variable as an evaluation metric and our goal will be to minimize it (instead of maximizing accuracy).  Recall what this does is measure the average squared difference between the predicted and actual values (which makes the error positive) and then takes the square root to return to the original units.\n",
    "\n",
    "Let's use the trained model to make predictions on the test data and calculate the MSE.  Scikit-learn provides a convenient function called `root_mean_squared_error()` in the `sklearn.metrics` module to calculate MSE.  It takes two arguments: the true values and the predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1740111883718,
     "user": {
      "displayName": "Ronni Kurtzhals",
      "userId": "06703412593860866078"
     },
     "user_tz": 360
    },
    "id": "QoKCUGjHwA_t",
    "outputId": "146ccaa8-e272-4fcf-b124-e893580699ce"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "# TODO: Use the trained model to make predictions on the test set\n",
    "y_pred = pricing_model.predict(X_test.values)\n",
    "\n",
    "# TODO: Compute Root Mean Squared Error (RMSE) which compares y_test and \n",
    "# y_pred\n",
    "rmse = root_mean_squared_error(...)\n",
    "print(f\"Root Mean Squared Error: {rmse:.10f}\")\n",
    "\n",
    "# TODO: Remember the unit of the target variable is $100,000s, print\n",
    "# the RMSE in dollars\n",
    "print(f\"RMSE in Dollars: ${...}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "573tkVDZwDZP"
   },
   "source": [
    "**Question:**:** Is the error acceptable for a real-world housing price prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "ENTER YOUR ANSWER HERE\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2W5bpfoUSTD-"
   },
   "source": [
    "### Step 5: Addressing Overfitting by Experimenting with `max_depth`\n",
    "\n",
    "With 21 levels, our decision tree regressor is likely overfitting the training data, essentially memorizing it rather than learning general patterns. One way to address overfitting is to limit the depth of the tree using the `max_depth` parameter when initializing the `DecisionTreeRegressor`. By restricting the depth, we can prevent the model from becoming too complex and help it generalize better to unseen data.\n",
    "\n",
    "This limiting of the tree depth is a form of **regularization**, which is a technique used to reduce overfitting by adding constraints to the model. Since we are limiting the breadth of the tree, this is typically called **pruning** in decision tree terminology. We will explore how changing the `max_depth` parameter affects the model's performance, but be aware there are **pruning techniques** that can be applied after the tree is built that prune specific branches of the tree rather than limiting the overall depth.\n",
    "\n",
    "Let's mess around a bit with these parameters and check out what it does. Your task here is to train decision trees and:\n",
    "\n",
    "- Limit the **depth of the tree** to prevent overfitting using the `max_depth` parameter of `DecisionTreeRegressor`.\n",
    "- Compare **RMSE at different depths**.\n",
    "\n",
    "**Question**: Get the following cell working and then explain in the comments what the resulting plot is showing you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 429,
     "status": "ok",
     "timestamp": 1740112005975,
     "user": {
      "displayName": "Ronni Kurtzhals",
      "userId": "06703412593860866078"
     },
     "user_tz": 360
    },
    "id": "q5mSvOYnwfx2",
    "outputId": "da83bcf4-d41d-4c4a-8d1a-3a09f2225add"
   },
   "outputs": [],
   "source": [
    "# TODO: Explain what depths are being tested here (Replace this comment\n",
    "# with your explanation)\n",
    "depths = range(1, pricing_model.get_depth() + 1)\n",
    "\n",
    "# Make lists to save depths and corresponding RMSEs\n",
    "depths_list = []\n",
    "rmse_list = []\n",
    "\n",
    "for depth in depths:\n",
    "    # TODO: Initialize a Decision Tree with max_depth = depth\n",
    "    pruned_pricing_model = DecisionTreeRegressor(max_depth=...)\n",
    "\n",
    "    # TODO: Train the model\n",
    "    pruned_pricing_model.fit(...)\n",
    "\n",
    "    # TODO: Make predictions and compute RMSE\n",
    "    y_pred = pruned_pricing_model.predict(...)\n",
    "    rmse = root_mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    # Save depth and RMSE to lists\n",
    "    depths_list.append(depth)\n",
    "    rmse_list.append(rmse)\n",
    "\n",
    "# Plot depth vs RMSE\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(depths_list, rmse_list, marker='o')\n",
    "plt.title('Decision Tree Depth vs RMSE', fontsize=16)\n",
    "plt.xlabel('Tree Depth', fontsize=14)\n",
    "plt.ylabel('Root Mean Squared Error (RMSE)', fontsize=14)\n",
    "plt.xticks(depths_list)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# TODO: Once you have the code working, explain what the plot is showing you\n",
    "# below (in place of this comment)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V2QWF5sOXOkE"
   },
   "source": [
    "**Question**: What is the optimal tree depth based on the plot?  Why do you think this tree is better than the full depth tree we built earlier?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "ENTER YOUR ANSWER HERE.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GlL6q2vrTUsL"
   },
   "source": [
    "## What you need to submit\n",
    "\n",
    "Once you have completed this lab, you need to submit your work. You should submit the `.ipynb` notebook file. To do this, go to the File menu and select **Download > Download .ipynb** (this is the native Jupyter notebook format).  Submit that file to the Lab 5 dropbox on D2L."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPCU48x6ALhbEj3tpV4ZBjU",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
